---
# yamllint disable rule:line-length
# yamllint disable rule:comments-indentation

# Proxy variables (optional) for download packages using a proxy server
proxy_env: {}
#  http_proxy: http://10.128.64.9:3128
#  https_proxy: http://10.128.64.9:3128

# -------------------------------------------

# Cluster variables
cluster_vip: "192.168.14.61"  # ip address for client access to databases in the cluster (optional)
vip_interface: "{{ ansible_default_ipv4.interface }}"  # interface name (ex. "ens32")

patroni_cluster_name: "postgres-cluster"  # specify the cluster name
patroni_install_version: "latest"  # or specific version (example 1.5.6)

patroni_superuser_username: "postgres"
patroni_superuser_password: "postgres-pass"  # please change password
patroni_replication_username: "replicator"
patroni_replication_password: "replicator-pass"  # please change password

synchronous_mode: false  # or 'true' for enable synchronous database replication
synchronous_mode_strict: false  # if 'true' then block all client writes to the master, when a synchronous replica is not available
synchronous_node_count: 1  # number of synchronous standby databases


# Load Balancing
with_haproxy_load_balancing: false  # or 'true' if you want to install and configure the load-balancing

# vip-manager (if cluster_vip is specified and with_haproxy_load_balancing: false)
vip_manager_version: "1.0"  # version to install
vip_manager_conf: "/etc/patroni/vip-manager.yml"
vip_manager_interval: "1000"  # time (in milliseconds) after which vip-manager wakes up and checks if it needs to register or release ip addresses.
vip_manager_iface: "{{ vip_interface }}"  # interface to which the virtual ip will be added
vip_manager_ip: "{{ cluster_vip }}"  # the virtual ip address to manage
vip_manager_mask: "24"  # netmask for the virtual ip


# DCS (Distributed Consensus Store)
dcs_exists: false  # or 'true' if you do not want to install and configure the etcd cluster
dcs_type: "etcd"

# if dcs_exists: false and dcs_type: "etcd"
etcd_ver: "v3.3.25"  # version for deploy etcd cluster
etcd_data_dir: "/var/lib/etcd"
etcd_cluster_name: "etcd-{{ patroni_cluster_name }}"  # ETCD_INITIAL_CLUSTER_TOKEN

# if dcs_exists: true and dcs_type: "etcd" - specify ip address your etcd cluster in the "patroni_etcd_hosts" variable
# example (use existing cluster of 3 nodes)
patroni_etcd_hosts: []
#  - { host: "10.128.64.140", port: "2379" }
#  - { host: "10.128.64.142", port: "2379" }
#  - { host: "10.128.64.143", port: "2379" }

# more options you can specify in the roles/patroni/templates/patroni.yml.j2
# https://patroni.readthedocs.io/en/latest/SETTINGS.html#etcd
# https://patroni.readthedocs.io/en/latest/SETTINGS.html#consul


# PostgreSQL variables
postgresql_version: "11"
# postgresql_data_dir: see vars/Debian.yml or vars/RedHat.yml
postgresql_port: "5432"
postgresql_encoding: "UTF8"  # for bootstrap only (initdb)
postgresql_locale: "en_US.UTF-8"  # for bootstrap only (initdb)
postgresql_data_checksums: true  # for bootstrap only (initdb)

# (optional) list of users to be created (if not already exists)
postgresql_users: []
#  - {name: "mydb-user", password: "mydb-user-pass"}
#  - {name: "", password: ""}
#  - {name: "", password: ""}
#  - {name: "", password: ""}

# (optional) list of databases to be created (if not already exists)
postgresql_databases: []
#  - {db: "mydatabase", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "mydb-user"}
#  - {db: "", encoding: "UTF8", lc_collate: "en_US.UTF-8", lc_ctype: "en_US.UTF-8", owner: ""}
#  - {db: "", encoding: "UTF8", lc_collate: "en_US.UTF-8", lc_ctype: "en_US.UTF-8", owner: ""}

# (optional) list of database extensions to be created (if not already exists)
postgresql_extensions: []
#  - {ext: "pg_stat_statements", db: "postgres"}
#  - {ext: "pg_stat_statements", db: "mydatabase"}
#  - {ext: "pg_stat_statements", db: ""}
#  - {ext: "pg_stat_statements", db: ""}
#  - {ext: "pg_repack", db: ""}  # postgresql-<version>-repack package is required
#  - {ext: "pg_stat_kcache", db: ""}  # postgresql-<version>-pg-stat-kcache package is required
#  - {ext: "", db: ""}
#  - {ext: "", db: ""}


# postgresql parameters to bootstrap dcs (are parameters for example)
postgresql_parameters:
  - {option: "max_connections", value: "100"}
  - {option: "superuser_reserved_connections", value: "5"}
  - {option: "max_locks_per_transaction", value: "64"}  # raise this value (ex. 512) if you have queries that touch many different tables (partitioning)
  - {option: "max_prepared_transactions", value: "0"}
  - {option: "huge_pages", value: "try"}  # or "on" if you set "vm_nr_hugepages" in kernel parameters
  - {option: "shared_buffers", value: "512MB"}  # please change this value
  - {option: "work_mem", value: "128MB"}  # please change this value
  - {option: "maintenance_work_mem", value: "256MB"}  # please change this value
  - {option: "effective_cache_size", value: "4GB"}  # please change this value
  - {option: "checkpoint_timeout", value: "15min"}
  - {option: "checkpoint_completion_target", value: "0.9"}
  - {option: "min_wal_size", value: "2GB"}  # for PostgreSQL 9.5 and above (for 9.4 use "checkpoint_segments")
  - {option: "max_wal_size", value: "4GB"}  # for PostgreSQL 9.5 and above (for 9.4 use "checkpoint_segments")
  - {option: "wal_buffers", value: "32MB"}
  - {option: "default_statistics_target", value: "1000"}
  - {option: "seq_page_cost", value: "1"}
  - {option: "random_page_cost", value: "4"}  # "1.1" for SSD storage. Also, if your databases fits in shared_buffers
  - {option: "effective_io_concurrency", value: "2"}  # "200" for SSD storage
  - {option: "synchronous_commit", value: "on"}  # or 'off' if you can you lose single transactions in case of a crash
  - {option: "autovacuum", value: "on"}  # never turn off the autovacuum!
  - {option: "autovacuum_max_workers", value: "5"}
  - {option: "autovacuum_vacuum_scale_factor", value: "0.01"}
  - {option: "autovacuum_analyze_scale_factor", value: "0.02"}
  - {option: "autovacuum_vacuum_cost_limit", value: "200"}  # or 500/1000
  - {option: "autovacuum_vacuum_cost_delay", value: "20"}
  - {option: "autovacuum_naptime", value: "1s"}
  - {option: "max_files_per_process", value: "4096"}
  - {option: "archive_mode", value: "on"}
  - {option: "archive_timeout", value: "1800s"}
  - {option: "archive_command", value: "cd ."}  # not doing anything yet with WAL-s
#  - {option: "archive_command", value: "wal-g wal-push %p"}  # archive WAL-s using WAL-G
#  - {option: "archive_command", value: "pgbackrest --stanza={{ pgbackrest_stanza }} archive-push %p"}  # archive WAL-s using pgbackrest
  - {option: "wal_level", value: "replica"}  # "replica" for PostgreSQL 9.6 and above (for 9.4, 9.5 use "hot_standby")
  - {option: "wal_keep_segments", value: "130"}
  - {option: "max_wal_senders", value: "10"}
  - {option: "max_replication_slots", value: "10"}
  - {option: "hot_standby", value: "on"}
  - {option: "wal_log_hints", value: "on"}
  - {option: "shared_preload_libraries", value: "pg_stat_statements,auto_explain"}
  - {option: "pg_stat_statements.max", value: "10000"}
  - {option: "pg_stat_statements.track", value: "all"}
  - {option: "pg_stat_statements.save", value: "off"}
  - {option: "auto_explain.log_min_duration", value: "10s"}  # 10 sec (by default). Decrease this value if necessary
  - {option: "auto_explain.log_analyze", value: "true"}
  - {option: "auto_explain.log_buffers", value: "true"}
  - {option: "auto_explain.log_timing", value: "false"}
  - {option: "auto_explain.log_triggers", value: "true"}
  - {option: "auto_explain.log_verbose", value: "true"}
  - {option: "auto_explain.log_nested_statements", value: "true"}
  - {option: "track_io_timing", value: "on"}
  - {option: "log_lock_waits", value: "on"}
  - {option: "log_temp_files", value: "0"}
  - {option: "track_activities", value: "on"}
  - {option: "track_counts", value: "on"}
  - {option: "track_functions", value: "all"}
  - {option: "log_checkpoints", value: "on"}
  - {option: "logging_collector", value: "on"}
  - {option: "log_truncate_on_rotation", value: "on"}
  - {option: "log_rotation_age", value: "1d"}
  - {option: "log_rotation_size", value: "0"}
  - {option: "log_line_prefix", value: "'%t [%p-%l] %r %q%u@%d '"}
  - {option: "log_filename", value: "'postgresql-%a.log'"}
  - {option: "log_directory", value: "{{ postgresql_log_dir }}"}
#  - {option: "idle_in_transaction_session_timeout", value: "600000"}  # for PostgreSQL 9.6 and above
#  - {option: "max_worker_processes", value: "24"}
#  - {option: "max_parallel_workers", value: "24"}  # for PostgreSQL 10 and above
#  - {option: "max_parallel_workers_per_gather", value: "4"}  # for PostgreSQL 9.6 and above
#  - {option: "max_parallel_maintenance_workers", value: "2"}  # for PostgreSQL 11 and above
#  - {option: "hot_standby_feedback", value: "on"}  # allows feedback from a hot standby to the primary that will avoid query conflicts
#  - {option: "max_standby_streaming_delay", value: "30s"}
#  - {option: "wal_receiver_status_interval", value: "10s"}
#  - {option: "old_snapshot_threshold", value: "60min"}  # for PostgreSQL 9.6 and above (1min-60d)
#  - {option: "", value: ""}
#  - {option: "", value: ""}


# specify additional hosts that will be added to the pg_hba.conf
postgresql_pg_hba:
  - {type: "local", database: "all", user: "postgres", address: "", method: "trust"}  # "local=trust" required for ansible modules "postgresql_(user,db,ext)"
  - {type: "local", database: "all", user: "all", address: "", method: "peer"}
  - {type: "host", database: "all", user: "all", address: "127.0.0.1/32", method: "md5"}
  - {type: "host", database: "all", user: "all", address: "::1/128", method: "md5"}
#  - {type: "host", database: "mydatabase", user: "mydb-user", address: "192.168.0.0/24", method: "md5"}
#  - {type: "host", database: "all", user: "all", address: "192.168.0.0/24", method: "ident", options: "map=main"}  # use pg_ident

# list of lines that Patroni will use to generate pg_ident.conf
postgresql_pg_ident: []
#  - {mapname: "main", system_username: "postgres", pg_username: "backup"}
#  - {mapname: "", system_username: "", pg_username: ""}


# PgBouncer parameters
pgbouncer_install: true  # or 'false' if you do not want to install and configure the pgbouncer service
pgbouncer_conf_dir: "/etc/pgbouncer"
pgbouncer_log_dir: "/var/log/pgbouncer"
pgbouncer_listen_port: 6432
pgbouncer_max_client_conn: 10000
pgbouncer_max_db_connections: 1000
pgbouncer_default_pool_size: 20
pgbouncer_default_pool_mode: "session"
pgbouncer_generate_userlist: true  # generate userlist.txt (all users and passwords md5) FROM pg_shadow

pgbouncer_pools:
  - {name: "postgres", dbname: "postgres", pool_parameters: ""}
#  - {name: "mydatabase", dbname: "mydatabase", pool_parameters: "pool_size=20 pool_mode=transaction"}
#  - {name: "", dbname: "", pool_parameters: ""}
#  - {name: "", dbname: "", pool_parameters: ""}


# Extended variables (optional)
patroni_ttl: 30
patroni_loop_wait: 10
patroni_retry_timeout: 10
patroni_maximum_lag_on_failover: 1048576
patroni_master_start_timeout: 300

patroni_postgresql_use_pg_rewind: true  # or 'false'
# try to use pg_rewind on the former leader when it joins cluster as a replica.

patroni_remove_data_directory_on_rewind_failure: false  # or 'true' (if use_pg_rewind: 'true')
# avoid removing the data directory on an unsuccessful rewind
# if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica.

patroni_remove_data_directory_on_diverged_timelines: false  # or 'true'
# if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica
# if it notices that timelines are diverging and the former master can not start streaming from the new master.

# https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#bootstrap
patroni_cluster_bootstrap_method: "initdb"  # or "wal-g", "pgbackrest"

# https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#building-replicas
patroni_create_replica_methods:
#  - pgbackrest
#  - wal_e
#  - wal_g
  - basebackup

pgbackrest:
  - {option: "command", value: "/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --delta restore"}
  - {option: "keep_data", value: "True"}
  - {option: "no_params", value: "True"}
wal_e:
  - {option: "command", value: "patroni_wale_restore"}
  - {option: "no_master", value: "1"}
  - {option: "envdir", value: "/etc/wal_e/envdir"}
  - {option: "use_iam", value: "1"}
wal_g:
  - {option: "command", value: "wal-g backup-fetch {{ postgresql_data_dir }} LATEST"}
  - {option: "no_params", value: "True"}
basebackup:
  - {option: "max-rate", value: "100M"}
  - {option: "checkpoint", value: "fast"}

# "restore_command" written to recovery.conf when configuring follower (create replica)
postgresql_restore_command: ""
# postgresql_restore_command: "wal-g wal-fetch %f %p"  # restore WAL-s using WAL-G
# postgresql_restore_command: "pgbackrest --stanza={{ pgbackrest_stanza }} archive-get %f %p"  # restore WAL-s using pgbackrest


# WAL-G
wal_g_install: false  # or 'true'
wal_g_ver: "v0.2.19"
wal_g_json:  # more options see https://github.com/wal-g/wal-g#configuration
  - {option: "AWS_ACCESS_KEY_ID", value: "minio"}
  - {option: "AWS_SECRET_ACCESS_KEY", value: "miniosecret"}
  - {option: "AWS_ENDPOINT", value: "http://172.26.9.200:9000"}
  - {option: "WALG_S3_PREFIX", value: "s3://bucket"}
  - {option: "AWS_S3_FORCE_PATH_STYLE", value: "true"}
  - {option: "WALG_COMPRESSION_METHOD", value: "brotli"}
  - {option: "PGDATA", value: "{{ postgresql_data_dir }}"}
  - {option: "PGHOST", value: "{{ postgresql_unix_socket_dir }}"}
#  - {option: "AWS_REGION", value: "us-east-1"}
#  - {option: "WALG_S3_CA_CERT_FILE", value: "/path/to/custom/ca/file"}
#  - {option: "", value: ""}
wal_g_patroni_cluster_bootstrap_command: "wal-g backup-fetch {{ postgresql_data_dir }} LATEST"

# pgBackRest
pgbackrest_install: false  # or 'true'
pgbackrest_install_from_pgdg_repo: true  # or 'false'
pgbackrest_stanza: "stanza_name"  # specify your --stanza
pgbackrest_repo_type: "posix"  # or "s3"
pgbackrest_repo_host: "10.128.64.50"  # dedicated repository host (if repo_type: "posix")
pgbackrest_repo_user: "postgres"  # if "repo_host" is set
pgbackrest_conf_file: "/etc/pgbackrest/pgbackrest.conf"
# see more options https://pgbackrest.org/configuration.html
pgbackrest_conf:
  global:  # [global] section
    - {option: "log-level-file", value: "detail"}
    - {option: "log-path", value: "/var/log/pgbackrest"}
    - {option: "repo1-type", value: "{{ pgbackrest_repo_type |lower }}"}
    - {option: "repo1-host", value: "{{ pgbackrest_repo_host }}"}
    - {option: "repo1-host-user", value: "{{ pgbackrest_repo_user }}"}
#    - {option: "", value: ""}
  stanza:  # [stanza_name] section
    - {option: "pg1-path", value: "{{ postgresql_data_dir }}"}
    - {option: "process-max", value: "2"}
    - {option: "recovery-option", value: "recovery_target_action=promote"}
#    - {option: "", value: ""}
pgbackrest_patroni_cluster_restore_command:
  '/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --delta restore'  # restore from latest backup
#  '/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --type=time "--target=2020-06-01 11:00:00+03" --delta restore'  # Point-in-Time Recovery (example)

# PITR mode (if patroni_cluster_bootstrap_method: "pgbackrest" or "wal-g"):
# 1) The database cluster directory will be cleaned (for "wal-g") or overwritten (for "pgbackrest" --delta restore).
# 2) And also the patroni cluster "{{ patroni_cluster_name }}" will be removed from the DCS (if exist) before recovery.

disable_archive_command: true  # or 'false' to not disable archive_command after restore
keep_patroni_dynamic_json: true  # or 'false' to remove patroni.dynamic.json after restore (if exists)

...
